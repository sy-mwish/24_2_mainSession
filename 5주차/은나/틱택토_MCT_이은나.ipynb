{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class State:\n",
        "    def __init__(self, my_actions=None, enemy_actions=None):\n",
        "        self.my_actions = my_actions if my_actions is not None else []\n",
        "        self.enemy_actions = enemy_actions if enemy_actions is not None else []\n",
        "        self.current_player = 'me'  # 첫 번째 플레이어 나로 초기화\n",
        "        self.board = self.create_board(self.my_actions, self.enemy_actions)\n",
        "\n",
        "    def create_board(self, my_actions, enemy_actions):\n",
        "        total_board = np.zeros(shape=(2, 3, 3))\n",
        "\n",
        "        # 각 플레이어의 말이 놓인 위치를 1로 표시\n",
        "        for action in my_actions:\n",
        "            row, col = divmod(action, 3)\n",
        "            total_board[0][row, col] = 1  # 나의 보드\n",
        "        for action in enemy_actions:\n",
        "            row, col = divmod(action, 3)\n",
        "            total_board[1][row, col] = 1  # 상대방 보드\n",
        "\n",
        "        return total_board\n",
        "\n",
        "    def available_moves(self):\n",
        "        # 나와 상대 모두 놓지 않은 빈 칸을 반환\n",
        "        total_occupied = self.board[0] + self.board[1]\n",
        "        available = np.argwhere(total_occupied == 0)\n",
        "        return [tuple(pos) for pos in available]\n",
        "\n",
        "    def next_state(self, action):\n",
        "        new_state = State(self.my_actions.copy(), self.enemy_actions.copy())\n",
        "        new_state.add_move(action)\n",
        "        new_state.current_player = self.switch_player(self.current_player)  # 플레이어 전환\n",
        "        return new_state\n",
        "\n",
        "    def add_move(self, action):\n",
        "        if self.current_player == 'me':\n",
        "            self.my_actions.append(action[0] * 3 + action[1])  # 2D 좌표를 1D로 변환하여 저장\n",
        "        else:\n",
        "            self.enemy_actions.append(action[0] * 3 + action[1])\n",
        "\n",
        "        # 보드 다시 생성\n",
        "        self.board = self.create_board(self.my_actions, self.enemy_actions)\n",
        "\n",
        "    def is_win(self, board):\n",
        "        vertical_win = np.any(np.all(board == 1, axis=0))  # 세로 줄 확인\n",
        "        horizontal_win = np.any(np.all(board == 1, axis=1))  # 가로 줄 확인\n",
        "        diagonal_win1 = np.all(np.diag(board) == 1)  # 첫 번째 대각선 확인\n",
        "        diagonal_win2 = np.all(np.diag(np.fliplr(board)) == 1)  # 두 번째 대각선 확인\n",
        "\n",
        "        # 하나라도 승리 조건을 만족하면 True 반환\n",
        "        return vertical_win or horizontal_win or diagonal_win1 or diagonal_win2\n",
        "\n",
        "    def is_lose(self):\n",
        "        return self.is_win(self.board[1])  # 상대방 보드에서 승리 여부 확인\n",
        "\n",
        "    def is_draw(self):\n",
        "        # 남은 칸이 없고, 나와 상대방 모두 승리하지 않은 경우 무승부\n",
        "        return len(self.available_moves()) == 0 and not self.is_win(self.board[0]) and not self.is_win(self.board[1])\n",
        "\n",
        "    def is_done(self):\n",
        "        return self.is_win(self.board[0]) or self.is_lose() or self.is_draw()\n",
        "\n",
        "    def switch_player(self, current_player):\n",
        "        return 'enemy' if current_player == 'me' else 'me'\n"
      ],
      "metadata": {
        "id": "NF3G2qK2e7Nw"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TicTacToeEnvironment:\n",
        "    def __init__(self):\n",
        "        self.state = State()  # 상태 초기화\n",
        "        self.board_size = (3, 3)\n",
        "        self.action_space = range(self.board_size[0] * self.board_size[1])  # 가능한 액션 공간 (9개의 칸)\n",
        "        self.n_actions = len(self.action_space)\n",
        "\n",
        "        # 보상 체계: 승리 시 1, 패배 시 -1, 무승부는 0, 진행 중에는 보상 없음\n",
        "        self.reward = {'win': 1, 'lose': -1, 'draw': 0, 'progress': 0}\n",
        "\n",
        "    def reset(self):\n",
        "        # 환경을 초기화하고 초기 상태 반환\n",
        "        self.state = State()  # 새로운 상태 객체로 초기화\n",
        "        return self.state\n",
        "\n",
        "    def step(self, action):\n",
        "        if action not in self.action_space:\n",
        "            raise ValueError(f\"Invalid action: {action}\")\n",
        "\n",
        "        # 1D action을 2D 좌표로 변환\n",
        "        row, col = divmod(action, self.board_size[1])\n",
        "\n",
        "        # 현재 플레이어가 선택한 위치에 말 두기\n",
        "        if (row, col) not in self.state.available_moves():\n",
        "            raise ValueError(f\"Invalid move: position ({row}, {col}) is already occupied\")\n",
        "\n",
        "        # 다음 상태로 전환\n",
        "        self.state = self.state.next_state((row, col))\n",
        "\n",
        "        # 게임 종료 여부 확인\n",
        "        done = self.state.is_done()\n",
        "\n",
        "        # 보상 계산\n",
        "        if self.state.is_win(self.state.board[0]):  # 내가 이긴 경우\n",
        "            reward = self.reward['win']\n",
        "        elif self.state.is_lose():  # 내가 진 경우\n",
        "            reward = self.reward['lose']\n",
        "        elif self.state.is_draw():  # 무승부인 경우\n",
        "            reward = self.reward['draw']\n",
        "        else:\n",
        "            reward = self.reward['progress']  # 게임이 아직 진행 중인 경우\n",
        "\n",
        "        return self.state, reward, done\n",
        "\n",
        "    def render(self):\n",
        "        # 3x3 보드를 생성하여 빈 칸은 ' ', 플레이어는 'X', AI는 'O'로 채운다\n",
        "        board = np.full((3, 3), ' ')\n",
        "\n",
        "        # 플레이어의 움직임('X')와 AI의 움직임('O')을 표시\n",
        "        for i in range(3):\n",
        "            for j in range(3):\n",
        "                if self.state.board[0][i][j] == 1:  # 플레이어의 말 'X'\n",
        "                    board[i][j] = 'X'\n",
        "                elif self.state.board[1][i][j] == 1:  # AI의 말 'O'\n",
        "                    board[i][j] = 'O'\n",
        "\n",
        "        # 3x3 보드 출력\n",
        "        for row in board:\n",
        "            print(\" | \".join(row))\n",
        "            print(\"-\" * 9)"
      ],
      "metadata": {
        "id": "fDo0ZSjjfFHp"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "\n",
        "class MCTSNode:\n",
        "    def __init__(self, state, parent=None, action=None):\n",
        "        self.state = state  # 현재 노드의 상태\n",
        "        self.parent = parent  # 부모 노드\n",
        "        self.action = action  # 부모로부터 이 노드로 오게 한 액션\n",
        "        self.children = []  # 자식 노드들\n",
        "        self.visits = 0  # 이 노드가 방문된 횟수\n",
        "        self.wins = 0  # 이 노드를 통한 승리 횟수\n",
        "\n",
        "    def is_fully_expanded(self):\n",
        "        # 자식 노드들이 다 생성되었는지 확인\n",
        "        return len(self.children) == len(self.state.available_moves())\n",
        "\n",
        "    def best_child(self, exploration_param=1.41):\n",
        "        # UCB1 공식을 이용해 가장 가치 있는 자식 노드를 반환\n",
        "        best_value = -float('inf')\n",
        "        best_node = None\n",
        "        for child in self.children:\n",
        "            # UCB1 계산\n",
        "            ucb1_value = (child.wins / child.visits) + exploration_param * math.sqrt(math.log(self.visits) / child.visits)\n",
        "            if ucb1_value > best_value:\n",
        "                best_value = ucb1_value\n",
        "                best_node = child\n",
        "        return best_node\n",
        "\n",
        "    def expand(self):\n",
        "        # 자식 노드가 없는 새로운 행동을 선택하고 확장\n",
        "        available_actions = self.state.available_moves()\n",
        "        for action in available_actions:\n",
        "            action_1d = action[0] * 3 + action[1]  # 2D action을 1D로 변환\n",
        "            if not any(child.action == action_1d for child in self.children):\n",
        "                # 새로운 자식 노드 생성\n",
        "                new_state = self.state.next_state(action)\n",
        "                child_node = MCTSNode(new_state, parent=self, action=action_1d)  # 1D action을 저장\n",
        "                self.children.append(child_node)\n",
        "                return child_node\n",
        "\n",
        "    def simulate(self):\n",
        "        # 랜덤 시뮬레이션을 통해 승리 여부 확인\n",
        "        current_simulation_state = self.state\n",
        "        while not current_simulation_state.is_done():\n",
        "            available_moves = current_simulation_state.available_moves()\n",
        "            action = random.choice(available_moves)  # 무작위로 액션 선택\n",
        "            current_simulation_state = current_simulation_state.next_state(action)\n",
        "\n",
        "        if current_simulation_state.is_win(current_simulation_state.board[0]):\n",
        "            return 1  # 승리\n",
        "        elif current_simulation_state.is_lose():\n",
        "            return -1  # 패배\n",
        "        else:\n",
        "            return 0  # 무승부\n",
        "\n",
        "\n",
        "    def backpropagate(self, result):\n",
        "        # 시뮬레이션 결과를 바탕으로 트리를 역방향으로 업데이트\n",
        "        self.visits += 1\n",
        "        self.wins += result\n",
        "        if self.parent:\n",
        "            self.parent.backpropagate(-result)  # 상대방의 입장에서는 결과를 뒤집어야 함\n",
        "\n",
        "class MCTSAgent:\n",
        "    def __init__(self, environment, iterations=1000):\n",
        "        self.environment = environment  # TicTacToe 환경\n",
        "        self.iterations = iterations  # 시뮬레이션 반복 횟수\n",
        "\n",
        "    def select_action(self, state):\n",
        "        root_node = MCTSNode(state)\n",
        "\n",
        "        for _ in range(self.iterations):\n",
        "            # MCTS 4단계: 선택, 확장, 시뮬레이션, 역전파\n",
        "            node = root_node\n",
        "            # 1. 선택 단계: 자식 중 가장 좋은 노드를 선택하며 내려감\n",
        "            while not node.state.is_done() and node.is_fully_expanded():\n",
        "                node = node.best_child()\n",
        "\n",
        "            # 2. 확장 단계: 자식 노드 확장\n",
        "            if not node.state.is_done() and not node.is_fully_expanded():\n",
        "                node = node.expand()\n",
        "\n",
        "            # 3. 시뮬레이션 단계: 랜덤하게 게임 끝까지 진행\n",
        "            result = node.simulate()\n",
        "\n",
        "            # 4. 역전파 단계: 결과를 부모 노드들로 전달하며 업데이트\n",
        "            node.backpropagate(result)\n",
        "\n",
        "        # 가장 많은 승리를 기록한 자식 노드를 선택\n",
        "        best_child = root_node.best_child(exploration_param=0)\n",
        "        return best_child.action  # 선택된 행동 반환\n"
      ],
      "metadata": {
        "id": "ooPqcnQHgt3Q"
      },
      "execution_count": 174,
      "outputs": []
    }
  ]
}